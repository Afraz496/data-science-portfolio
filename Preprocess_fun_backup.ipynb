{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9c211be-6ce4-45a9-81c6-cec9cb7de62d",
   "metadata": {},
   "source": [
    "Function to preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f55caff-2dc1-455f-b177-baf215ba87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2022\n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('src/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import logging\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import (\n",
    "    TimeSeriesSplit,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a45351-0518-4981-b77e-55794568c19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f364f039-ca66-484c-bef0-fce2c207cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare X_train, y_train, X_test, y_test\n",
    "def data_prep(df,target_variable):\n",
    "    features = df.columns.to_list()\n",
    "    features.remove(target_variable)\n",
    "    X = df[features]\n",
    "    y = df[[target_variable]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deed1f35-a106-46ad-9d5d-97d60e7ea457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_processor(X_train, target_variable):\n",
    "    \"\"\"\n",
    "    Applies Simple Imputer to Categorical Features\n",
    "    Applies One Hot Encoding to Categorical Features\n",
    "    Applies Quantile Scaling to Numeric Features\n",
    "    Returns and writes pickle file of the complete preprocessor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : numpy\n",
    "        dataset in NumPy format\n",
    "    Will create lists of numeric and categorical \n",
    "        variables using X_train df\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    preprocessor : sklearn.Preprocessor\n",
    "        sklearn preprocessor fit on the training set\n",
    "    \"\"\"\n",
    "    \n",
    "    features = X_train.columns.to_list()\n",
    "    df_numeric_features = X_train.select_dtypes(include='number')\n",
    "    df_categorical_features = X_train.select_dtypes(include='object')\n",
    "\n",
    "    numeric_features = df_numeric_features.columns.to_list()\n",
    "    categorical_features = df_categorical_features.columns.to_list()\n",
    "    \n",
    "    pipe_num = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='mean')),\n",
    "        ('scaler',  MinMaxScaler())\n",
    "    ])\n",
    "    pipe_cat = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ]) \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', pipe_num, numeric_features),\n",
    "        ('cat', pipe_cat, categorical_features)\n",
    "    ])\n",
    "\n",
    "    norm_X_train = preprocessor.fit(X_train)\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe167de-e6ea-46fc-842a-b72418935e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42cdf22c-4f32-41fa-b51c-b978a05bc536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --file FILE\n",
      "ipykernel_launcher.py: error: the following arguments are required: --file\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#import argparse\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--file', type=str, required=True, help='Path to the CSV file')\n",
    "#args = parser.parse_args()\n",
    "#train_df = pd.read_csv(args.file)\n",
    "#Run the following command on cmd using your file name\n",
    "#python your_script.py --file result.csv \n",
    "\n",
    "train_df = pd.read_csv('result.csv') #read your dataset\n",
    "target_variable='validation_loss' #define your target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91767aa-dfd5-4d0a-ac89-ece6d41f5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_prep(train_df,target_variable)\n",
    "processor = fit_processor(train_df,target_variable)\n",
    "norm_X_train = processor.transform(X_train)\n",
    "norm_X_test = processor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b208af5f-f89a-451c-b81b-4928a66e3964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49bb2fa-3edd-41fc-a534-6e9b8d757a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
